{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection for Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection for linear regression to predict GII (Gender inequality Index)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from itertools import chain, combinations\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.stats import zscore\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import Lasso \n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "\n",
    "\n",
    "#returns dataframes containing independent variables, dependent variables, continent data\n",
    "def preprocessing(data, remove=[], dep_name='', normalize = False ):\n",
    "    data= data.replace('..', np.nan)\n",
    "    \n",
    "    # shuffle data\n",
    "\n",
    "    data = data.sample(frac=1)\n",
    "\n",
    "    # Separate continent data (unused)\n",
    "    continent_data = data.iloc[188:197]\n",
    "    data = data.iloc[0:188]\n",
    "    \n",
    "    # remove unused columns\n",
    "    data = data.drop(columns=remove)\n",
    "    \n",
    "    # Dataframe containing independent variables\n",
    "    \n",
    "    ind = data.drop(columns=[dep_name])\n",
    "\n",
    "    # Separate independent variable (target)\n",
    "    allbutdep = list(data.columns)\n",
    "    allbutdep.remove(dep_name)\n",
    "    dep = data.drop(columns=allbutdep)\n",
    "\n",
    "    # fill missing field with corresponding column's median\n",
    "    for i in ind.columns:\n",
    "        ind[i].fillna(ind[i].median(), inplace = True)\n",
    "    \n",
    "    dep.fillna(dep.median(), inplace = True)\n",
    "    \n",
    "    if(normalize):\n",
    "    # normalize data\n",
    "        scaler = MinMaxScaler() \n",
    "        scaled_values = scaler.fit_transform(ind) \n",
    "        ind.loc[:,:] = scaled_values\n",
    "    \n",
    "    \n",
    "    return ind, dep, continent_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regresion model\n",
    "lm = linear_model.LinearRegression()\n",
    "\n",
    "#lasso\n",
    "lasso_ridge = {'alpha':[1e-15,1e-10,1e-8,1e-3,1e-2,1,5,10,20]}\n",
    "lasso = linear_model.Lasso(max_iter=1000000, tol=.1)\n",
    "lasso_regressor = GridSearchCV(lasso,lasso_ridge, scoring='r2',cv=5)\n",
    "\n",
    "# Ridge\n",
    "ridge = linear_model.Ridge()\n",
    "ridge_regressor = GridSearchCV(ridge,lasso_ridge, scoring='r2',cv=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identifying features that produce high coefficients of determination (R^2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that generates powerset of a list\n",
    "def powerset(iterable):\n",
    "    s = list(iterable)\n",
    "    return list(chain.from_iterable(combinations(s, r) for r in range(len(s)+1)))\n",
    "\n",
    "# tentative: use correlation coefficient (matthews_corrcoef)\n",
    "\n",
    "#return list with all possible combination of features and R^2 score\n",
    "def feature_select(independent, dependent, regression= 'linear', num_results = 20):\n",
    "    # Generate powerset of independet variables \n",
    "    ind_vars = list(independent.columns)\n",
    "    PS_ind_vars= powerset(ind_vars)\n",
    "    PS_ind_vars = PS_ind_vars[len(dependent.columns)+1:]\n",
    "    \n",
    "    # number of sets in superset\n",
    "    PS_cardinality = len(PS_ind_vars)\n",
    "    print('Generating superset of cardinality=', PS_cardinality,'for',regression,'regression')\n",
    "    \n",
    "    #print('top '+ str(num_results)+':\\n')\n",
    "    \n",
    "    # tuple to list\n",
    "    for i in range(len(PS_ind_vars)):\n",
    "            PS_ind_vars[i] = list(PS_ind_vars[i])\n",
    "            \n",
    "    var_scores = []\n",
    "    #count= 0\n",
    "    # Store feature subset and score obtained using cross validation\n",
    "    for i in PS_ind_vars:\n",
    "        current_ds = independent[i]\n",
    "        if(regression=='linear'):\n",
    "            current_score = cross_val_score(lm, current_ds, dependent, scoring='r2', cv=5)\n",
    "            var_scores.append([i,current_score.mean(), lm])\n",
    "        elif(regression=='lasso'):\n",
    "            #print(count,end='-')\n",
    "            #count+=1\n",
    "            lasso_regressor.fit(current_ds,dependent)\n",
    "            var_scores.append([i,lasso_regressor.best_score_, lasso_regressor])\n",
    "        elif(regression=='ridge'):\n",
    "            #print(count,end='-')\n",
    "            #count+=1\n",
    "            ridge_regressor.fit(current_ds,dependent)\n",
    "            var_scores.append([i,ridge_regressor.best_score_, ridge_regressor])\n",
    "            \n",
    "        \n",
    "        \n",
    "    #sort based on score\n",
    "    var_scores.sort(key = lambda x: x[1], reverse = True)\n",
    "\n",
    "    # Number of top results to display\n",
    "    top_vars = num_results\n",
    "    var_scores =var_scores[:top_vars+1]\n",
    "    \n",
    "    print('Done')\n",
    "    return var_scores\n",
    "\n",
    "# Display combination of features and corresponding score\n",
    "def feature_display(var_scores, show_index = True):\n",
    "    index = 0\n",
    "    for i in var_scores:\n",
    "        if(show_index):\n",
    "            print('index:',index)\n",
    "        print('variables (',len(i[0]),'):')\n",
    "        for j in i[0]:\n",
    "            print('\\t',j)\n",
    "        print('R^2 score: ', i[1],'\\n')\n",
    "        index+=1\n",
    "\n",
    "# Display best combination of features     \n",
    "def highest_score_num_features(num, scores, display = False):\n",
    "    for i in range(len(scores)):\n",
    "        if (len(scores[i][0]) == num):\n",
    "            if(display):\n",
    "                print('best combination of features: \\nindex: ', i)\n",
    "                feature_display([scores[i]],False)\n",
    "            return i \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating superset of cardinality= 126 for linear regression\n",
      "Done\n",
      "Generating superset of cardinality= 126 for lasso regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel_AFA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5288208106837827, tolerance: 0.42457583576158947\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Generating superset of cardinality= 126 for ridge regression\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "GII_data = pd.read_csv('gender_inequality.csv')\n",
    "\n",
    "# independet feature name\n",
    "GII_ind_variable = 'Gender Inequality Index (GII)'\n",
    "\n",
    "# Features that will not be used\n",
    "GII_remove =['GII Rank', 'Country']\n",
    "\n",
    "# preprocessing\n",
    "GII_in, GII,GII_continent = preprocessing(GII_data,GII_remove,GII_ind_variable)\n",
    "\n",
    "# Generate scores\n",
    "GII_scores = feature_select(GII_in, GII)\n",
    "\n",
    "#feature_display(GII_scores)\n",
    "\n",
    "GII_lasso_scores =feature_select(GII_in, GII, 'lasso')\n",
    "\n",
    "#feature_display(GII_lasso_scores)\n",
    "\n",
    "GII_ridge_scores =feature_select(GII_in, GII, 'ridge')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t==Using linear regression==\n",
      "\n",
      "best combination of features: \n",
      "index:  9\n",
      "variables ( 3 ):\n",
      "\t Adolescent Birth Rate\n",
      "\t Percent Representation in Parliament\n",
      "\t Population with Secondary Education (Female)\n",
      "R^2 score:  0.7397194327344839 \n",
      "\n",
      "\t==Using lasso regression==\n",
      "\n",
      "best combination of features: \n",
      "index:  11\n",
      "variables ( 3 ):\n",
      "\t Adolescent Birth Rate\n",
      "\t Percent Representation in Parliament\n",
      "\t Population with Secondary Education (Female)\n",
      "R^2 score:  0.740112489215803 \n",
      "\n",
      "\t==Using ridge regression==\n",
      "\n",
      "best combination of features: \n",
      "index:  9\n",
      "variables ( 3 ):\n",
      "\t Adolescent Birth Rate\n",
      "\t Percent Representation in Parliament\n",
      "\t Population with Secondary Education (Female)\n",
      "R^2 score:  0.7401165864225664 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display best combination of features\n",
    "\n",
    "print('\\t==Using linear regression==\\n')\n",
    "best_GII_i = highest_score_num_features(3, GII_scores, True)\n",
    "print('\\t==Using lasso regression==\\n')\n",
    "best_GII_i_lasso= highest_score_num_features(3, GII_lasso_scores, True)\n",
    "print('\\t==Using ridge regression==\\n')\n",
    "best_GII_i_ridge= highest_score_num_features(3, GII_ridge_scores, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80-20 R^2 score: 0.6650160502031258\n",
      "Norway-> predicted:  [[0.0969324]] actual: 0.067\n",
      "Niger-> predicted: [[0.83691163]] actual: 0.713\n"
     ]
    }
   ],
   "source": [
    "# 80-20 split\n",
    "\n",
    "GII_test = GII_in[GII_scores[best_GII_i][0]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(GII_test, GII, test_size=0.20)\n",
    "\n",
    "GII_split = lm.fit(X_train, y_train)\n",
    "prediction = GII_split.predict(X_test)\n",
    "print('80-20 R^2 score:', r2_score(y_test, prediction))\n",
    "\n",
    "# Values corresponding to highest and lowest ranked country \n",
    "ideal_x = GII_data[GII_scores[best_GII_i][0]].iloc[0].values\n",
    "ideal_x = [float(i) for i in ideal_x]\n",
    "ideal_x = np.reshape(ideal_x,(1,-1)) #[7.8,39.6, 97.4]\n",
    "\n",
    "worst_x = list(GII_data[GII_scores[best_GII_i][0]].iloc[187])\n",
    "worst_x = [float(i) for i in worst_x]\n",
    "worst_x = np.reshape(worst_x,(1,-1))\n",
    "\n",
    "# Final training before prediction\n",
    "GII_lm = lm.fit(GII_test, GII)\n",
    "high_pred = GII_lm.predict(ideal_x)\n",
    "low_pred = GII_lm.predict(worst_x)\n",
    "\n",
    "print('Norway-> predicted: ',high_pred, 'actual:',GII_data.iloc[0].values[2])\n",
    "print('Niger-> predicted:',low_pred, 'actual:',GII_data.iloc[187].values[2])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection for linear regression to predict GDI (Gender development Index)\n",
    "\n",
    "\n",
    "# import data\n",
    "GDI_data = pd.read_csv('gender_development.csv')\n",
    "\n",
    "# independet feature name\n",
    "GDI_ind_variable = 'Gender Development Index (GDI)'\n",
    "\n",
    "# Features that will not be used\n",
    "GDI_remove =['GDI Rank', 'Country']\n",
    "\n",
    "# preprocessing \n",
    "GDI_in, GDI,GDI_continent = preprocessing(GDI_data,GDI_remove,GDI_ind_variable)\n",
    "# generate combination of features\n",
    "GDI_scores = feature_select(GDI_in, GDI,'linear',50)\n",
    "\n",
    "#feature_display(GDI_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display best combination \n",
    "best_GDI_i = highest_score_num_features(5, GDI_scores, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human Development Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "HDI_data = pd.read_csv('human_development.csv')\n",
    "\n",
    "HDI_data['Gross National Income (GNI) per Capita']= HDI_data['Gross National Income (GNI) per Capita'].apply(lambda x: float(x.replace(',','')))\n",
    "\n",
    "# independet feature name\n",
    "HDI_ind_variable = 'Human Development Index (HDI)'\n",
    "\n",
    "# Features that will not be used\n",
    "HDI_remove =['HDI Rank', 'Country']\n",
    "\n",
    "HDI_in, HDI,HDI_continent = preprocessing(HDI_data,HDI_remove,HDI_ind_variable)\n",
    "\n",
    "HDI_scores = feature_select(HDI_in, HDI, 'linear',20)\n",
    "\n",
    "#feature_display(HDI_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_HDI_i = highest_score_num_features(2, HDI_scores, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
